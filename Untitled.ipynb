{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from time import time\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_files = os.listdir('./state_union')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorpusDataLoader:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.data_folder = './state_union/'\n",
    "        pass\n",
    "    \n",
    "    def get_filenames(self):\n",
    "        return sorted(os.listdir(self.data_folder))\n",
    "    \n",
    "    def read_all_speeches(self):\n",
    "        self.corpus = []\n",
    "        for i, speech in enumerate(self.get_filenames()):\n",
    "            self.corpus.append(self.read_speech(speech))\n",
    "            logging.info(\"Read {0}\".format(speech))\n",
    "    \n",
    "    def read_speech(self, speech_filename):\n",
    "        with open(self.data_folder + speech_filename, \"rb\") as file:\n",
    "            text = file.read()\n",
    "            if type(text) is not str:\n",
    "                try:\n",
    "                    text = text.decode(\"utf-8\")\n",
    "                except:\n",
    "                    text = text.decode(\"iso-8859-1\")\n",
    "            return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = CorpusDataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Read 1945-Truman.txt\n",
      "INFO:root:Read 1946-Truman.txt\n",
      "INFO:root:Read 1947-Truman.txt\n",
      "INFO:root:Read 1948-Truman.txt\n",
      "INFO:root:Read 1949-Truman.txt\n",
      "INFO:root:Read 1950-Truman.txt\n",
      "INFO:root:Read 1951-Truman.txt\n",
      "INFO:root:Read 1953-Eisenhower.txt\n",
      "INFO:root:Read 1954-Eisenhower.txt\n",
      "INFO:root:Read 1955-Eisenhower.txt\n",
      "INFO:root:Read 1956-Eisenhower.txt\n",
      "INFO:root:Read 1957-Eisenhower.txt\n",
      "INFO:root:Read 1958-Eisenhower.txt\n",
      "INFO:root:Read 1959-Eisenhower.txt\n",
      "INFO:root:Read 1960-Eisenhower.txt\n",
      "INFO:root:Read 1961-Kennedy.txt\n",
      "INFO:root:Read 1962-Kennedy.txt\n",
      "INFO:root:Read 1963-Johnson.txt\n",
      "INFO:root:Read 1963-Kennedy.txt\n",
      "INFO:root:Read 1964-Johnson.txt\n",
      "INFO:root:Read 1965-Johnson-1.txt\n",
      "INFO:root:Read 1965-Johnson-2.txt\n",
      "INFO:root:Read 1966-Johnson.txt\n",
      "INFO:root:Read 1967-Johnson.txt\n",
      "INFO:root:Read 1968-Johnson.txt\n",
      "INFO:root:Read 1969-Johnson.txt\n",
      "INFO:root:Read 1970-Nixon.txt\n",
      "INFO:root:Read 1971-Nixon.txt\n",
      "INFO:root:Read 1972-Nixon.txt\n",
      "INFO:root:Read 1973-Nixon.txt\n",
      "INFO:root:Read 1974-Nixon.txt\n",
      "INFO:root:Read 1975-Ford.txt\n",
      "INFO:root:Read 1976-Ford.txt\n",
      "INFO:root:Read 1977-Ford.txt\n",
      "INFO:root:Read 1978-Carter.txt\n",
      "INFO:root:Read 1979-Carter.txt\n",
      "INFO:root:Read 1980-Carter.txt\n",
      "INFO:root:Read 1981-Reagan.txt\n",
      "INFO:root:Read 1982-Reagan.txt\n",
      "INFO:root:Read 1983-Reagan.txt\n",
      "INFO:root:Read 1984-Reagan.txt\n",
      "INFO:root:Read 1985-Reagan.txt\n",
      "INFO:root:Read 1986-Reagan.txt\n",
      "INFO:root:Read 1987-Reagan.txt\n",
      "INFO:root:Read 1988-Reagan.txt\n",
      "INFO:root:Read 1989-Bush.txt\n",
      "INFO:root:Read 1990-Bush.txt\n",
      "INFO:root:Read 1991-Bush-1.txt\n",
      "INFO:root:Read 1991-Bush-2.txt\n",
      "INFO:root:Read 1992-Bush.txt\n",
      "INFO:root:Read 1993-Clinton.txt\n",
      "INFO:root:Read 1994-Clinton.txt\n",
      "INFO:root:Read 1995-Clinton.txt\n",
      "INFO:root:Read 1996-Clinton.txt\n",
      "INFO:root:Read 1997-Clinton.txt\n",
      "INFO:root:Read 1998-Clinton.txt\n",
      "INFO:root:Read 1999-Clinton.txt\n",
      "INFO:root:Read 2000-Clinton.txt\n",
      "INFO:root:Read 2001-GWBush-1.txt\n",
      "INFO:root:Read 2001-GWBush-2.txt\n",
      "INFO:root:Read 2002-GWBush.txt\n",
      "INFO:root:Read 2003-GWBush.txt\n",
      "INFO:root:Read 2004-GWBush.txt\n",
      "INFO:root:Read 2005-GWBush.txt\n",
      "INFO:root:Read 2006-GWBush.txt\n"
     ]
    }
   ],
   "source": [
    "dataloader.read_all_speeches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=0.5, min_df=2, stop_words='english',\n",
    "                                 use_idf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 65, n_features: 7040\n"
     ]
    }
   ],
   "source": [
    "X = vectorizer.fit_transform(dataloader.corpus)\n",
    "print(\"n_samples: %d, n_features: %d\" % X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "km = KMeans(n_clusters=10, init='k-means++', max_iter=100, n_init=1,\n",
    "                verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering sparse data with KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=100,\n",
      "    n_clusters=10, n_init=1, n_jobs=1, precompute_distances='auto',\n",
      "    random_state=None, tol=0.0001, verbose=True)\n",
      "Initialization complete\n",
      "Iteration  0, inertia 78.847\n",
      "Iteration  1, inertia 41.690\n",
      "Converged at iteration 1: center shift 0.000000e+00 within tolerance 1.228991e-08\n",
      "done in 0.096s\n"
     ]
    }
   ],
   "source": [
    "print(\"Clustering sparse data with %s\" % km)\n",
    "t0 = time()\n",
    "km.fit(X)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: parents 21st pass college ought tell don got ll idea\n",
      "Cluster 1: space alliance kennedy john dream nam viet divisions communist atlantic\n",
      "Cluster 2: 1947 1946 veterans management expenditures 1945 adequate industrial bargaining collective\n",
      "Cluster 3: oil salt strategic gulf israel foundation region conflict canal barrels\n",
      "Cluster 4: peoples recommendations expenditures organization recommend communist general atomic field agriculture\n",
      "Cluster 5: xand xa 1974 seventies property 92d localities xthe sixties truly\n",
      "Cluster 6: applause terrorists terror iraq afghanistan terrorist qaeda al iraqi regime\n",
      "Cluster 7: vietnam recommend try 1968 south abundance consumer 1966 communist 1967\n",
      "Cluster 8: 1973 messages series outline lesson 1970s xall affairs notion credibility\n",
      "Cluster 9: ll space deficits recovery regulations don 1982 dreams waste bipartisan\n"
     ]
    }
   ],
   "source": [
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(10):\n",
    "    print(\"Cluster %d:\" % i, end='')\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind], end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
